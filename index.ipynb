{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Company A will soon be releasing a new mobile phone. They are concerned about its reception in the market and would like a way to monitor it.\n",
    "\n",
    "I will be building a Sentiment Analysis model to classify tweets as positive, negative or neutral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is provided by [CrowdFlower](https://data.world/crowdflower) and is available for download from [data.world](https://data.world/crowdflower/brands-and-product-emotions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA and Data Cleaning is in [eda.ipynb](eda.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Processing is in [text_preprocessing.ipynb](text_preprocessing.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A series of classification models were run on the data and evaluated based upon Average Macro Recall, a balanced Recall score for each class, and overall accuracy in descending order of importance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Baseline - Naive Bayes with Word Vectors](baseline_model.ipynb)\n",
    "* Naive Bayes tuned with Min Doc Freq\n",
    "    * [Word Vectors](nb_model_01.ipynb)\n",
    "    * [Word Vectors, Bi-Grams](nb_model_02.ipynb)\n",
    "    * [Tf/Idf](nb_model_03.ipynb)\n",
    "    * [Tf/Idf, with SMOTE oversampling](nb_model_04.ipynb)\n",
    "    * [Tf/Idf, with Lemmatization](nb_model_05.ipynb)\n",
    "    * [Tf/Idf with SMOTE oversampling and Lemmatization](nb_model_06.ipynb)\n",
    "    * [TF/Idf with Bi-Grams, SMOTE oversampling and Lemmatization](nb_model_07.ipynb)\n",
    "* Support Vector Machines tuned with Min Doc Freq\n",
    "    * [Tf/Idf](smv_model_01.ipynb)\n",
    "    * [Tf/Idf with SMOTE oversampling](smv_model_02.ipynb)\n",
    "    * [Tf/Idf with SMOTE oversampling and Lemmatization](smv_model_03.ipynb)\n",
    "* Neural Networks using Word Embeddings\n",
    "    * [Single Embedding Layer with 8 nodes](emb_model_01.ipynb)\n",
    "    * [Single Embedding Layer with 100 nodes](emb_model_02.ipynb)\n",
    "    * [Single Embedding Layer with 100 nodes, with Lemmatization](emb_model_02-lemma.ipynb)\n",
    "    * [Single Embedding Layer with 200 nodes](emb_model_03.ipynb)\n",
    "    * [Single Embedding Layer using GloVe pretrained embeddings](emb_model_04.ipynb)\n",
    "    * [Single Embedding Layer using GloVe pretrained embeddings, with Lemmatization](emb_model_04-lemma.ipynb)\n",
    "    * [Deep Network using GloVe pretrained embeddings](emb_model_05.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A summary of the model performance metrics can be found [here](model_performance_summary.ipynb).\n",
    "\n",
    "The model that performed the best was a Naive Bayes Classifier that used tf/idf, SMOTE oversampling, lemmatization of the tokens and was tuned with minimum document frequency.  It's notebook can be found [here](nb_model_06.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Using a Naive Bayes Classifier, I achieved an macro average recall score of 0.61, balanced recall scores of 0.61, 0.56 and 0.67 for Negative, Neutral and Positive classes respectively, and an overall accuracy of 60%\n",
    "\n",
    "\n",
    "* While not the greatest accuracy, automating Twitter sentiment analysis will be a step in the right direction in terms of efficiently monitoring the sentiment of Twitter users towards Company A's new mobile phone."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I recommend that Company A use Twitter's API to filter tweets with hashtags and text deemed to be related to their mobile phone. These tweets can then be classified by the model and monitored to keep track of the current sentiment regarding their phone.\n",
    "\n",
    "\n",
    "* Building upon the previous recommendation, an alert system can be created to monitor for changes in sentiment so that they can be addressed quickly.\n",
    "\n",
    "\n",
    "* Use the model to monitor sentiment regarding the mobile phone industry in general, as well as the sentiment towards competing products."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-04T17:20:57.684030Z",
     "start_time": "2020-09-04T17:20:57.679613Z"
    }
   },
   "source": [
    "* Acquire more labeled Tweets to improve the model\n",
    "\n",
    "The dataset used to train this model is relatively small, about 8500 tweets.  Retraining the model on a larger dataset should improve its performance.\n",
    "\n",
    "* Expand the scope of the sentiment analysis monitoring\n",
    "\n",
    "There is plenty of other publicly available text data that can be acquired and monitored for sentiment.  This data may be on other social media platforms or public forums, or could be product reviews. While product reviews often have an associated rating, that rating may differ from the overall sentiment of the review.  Classifying this other data will require a new model because its structure would differ from a tweet.\n",
    "\n",
    "* Add granularity to the sentiment analysis\n",
    "\n",
    "Some text data is going to be more negative or more positive than others.  By creating a scale from very negative to somewhat negative to neutral to somewhat positive to very positive, more nuance will be able to be found in the sentiment analysis, and actions can be taken based on the severity of the situation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
