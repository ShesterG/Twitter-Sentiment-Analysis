{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "learn-env",
      "language": "python",
      "name": "learn-env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "02_text_preprocessing.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShesterG/Twitter-Sentiment-Analysis/blob/master/notebooks/02_text_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWj_6vRQcIhQ"
      },
      "source": [
        "# Text Preprocessing for Twitter Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQTwCck2y55n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4a136e5-36a8-4972-e24f-b1bb030d9b13"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-W9yM2YCcIhd"
      },
      "source": [
        "# Imports and Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:45.050110Z",
          "start_time": "2020-09-17T19:00:43.770359Z"
        },
        "id": "fzxCSJvicIhf"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk import FreqDist\n",
        "import string"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:45.056796Z",
          "start_time": "2020-09-17T19:00:45.052662Z"
        },
        "id": "hzjNrkwfcIhi"
      },
      "source": [
        "DATA_FILE_PATH = '/content/drive/MyDrive/NLPGh/'\n",
        "CLEAN_DATA_FILE_NAME = 'NALS1Clean.csv'\n",
        "SAVE_FILE = True\n",
        "TOKENIZED_DATA_FILE_NAME = 'NALS1Tokenized.csv'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xW_HYH7cIhj"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:45.092191Z",
          "start_time": "2020-09-17T19:00:45.059527Z"
        },
        "id": "Hb-WRYrVcIhk"
      },
      "source": [
        "df = pd.read_csv(DATA_FILE_PATH + CLEAN_DATA_FILE_NAME)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:45.122879Z",
          "start_time": "2020-09-17T19:00:45.094914Z"
        },
        "id": "jvv1nUCEcIhm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "51245470-9b48-46a0-d7d4-60ef316d446b"
      },
      "source": [
        "pd.set_option('display.max_colwidth', None)\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>location</th>\n",
              "      <th>pretweet</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Pls add us some momo to make data  0246964913 Ã°Å¸ËâÃ°Å¸ËâÃ°Å¸Ëâ https://t.co/w5ozYUF59x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>pl add some momo make data 0246964913</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@McVan_1 @AnnanPerry @blac4rina We will descend on @NAkufoAddo soon</td>\n",
              "      <td>Ghana</td>\n",
              "      <td>will descend soon</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>*Forgery allegations by EC is not enough to disqualify the five presidential candidates*\\n\\nhttps://t.co/GAkYghEbQHÃ¢â¬Â¦ https://t.co/o0pCodbuWj</td>\n",
              "      <td>NaN</td>\n",
              "      <td>forgeri alleg not enough disqualifi the five presidenti candid</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@NiiWills @bosompemny I donÃ¢â¬â¢t know how dem dey see @NAkufoAddo oo</td>\n",
              "      <td>dansoman accra</td>\n",
              "      <td>dont know how dem dey see</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Do we have online renewal what what ka kwano?? https://t.co/3CdekJYMgr</td>\n",
              "      <td>Botswana</td>\n",
              "      <td>have onlin renew what what kwano</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                tweet  ... Sentiment\n",
              "0                                                   Pls add us some momo to make data  0246964913 Ã°Å¸ËâÃ°Å¸ËâÃ°Å¸Ëâ https://t.co/w5ozYUF59x  ...       0.0\n",
              "1                                                                                 @McVan_1 @AnnanPerry @blac4rina We will descend on @NAkufoAddo soon  ...       0.0\n",
              "2  *Forgery allegations by EC is not enough to disqualify the five presidential candidates*\\n\\nhttps://t.co/GAkYghEbQHÃ¢â¬Â¦ https://t.co/o0pCodbuWj  ...       0.0\n",
              "3                                                                            @NiiWills @bosompemny I donÃ¢â¬â¢t know how dem dey see @NAkufoAddo oo  ...       0.0\n",
              "4                                                                              Do we have online renewal what what ka kwano?? https://t.co/3CdekJYMgr  ...       0.0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXRpiseEcIhr"
      },
      "source": [
        "# Clean Tweet Text Data\n",
        "\n",
        "* Change all text to lowercase\n",
        "* Remove urls\n",
        "* Remove mentions\n",
        "* Remove placeholders {link} and \\[video\\]\n",
        "* Remove punctuation that isn't associated with emojis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:45.128513Z",
          "start_time": "2020-09-17T19:00:45.125151Z"
        },
        "id": "Rc6diSeQcIht"
      },
      "source": [
        "df_clean = df"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:45.147025Z",
          "start_time": "2020-09-17T19:00:45.130693Z"
        },
        "id": "pQAyc1RWcIhv"
      },
      "source": [
        "# lower case\n",
        "df_clean.pretweet = df_clean.pretweet.str.lower()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:45.171568Z",
          "start_time": "2020-09-17T19:00:45.149325Z"
        },
        "id": "HuFn_BfYcIhw"
      },
      "source": [
        "# remove url links\n",
        "df_clean.pretweet = df_clean.pretweet.apply(lambda x: re.sub(r'https?:\\/\\/\\S+', '', x))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:45.271491Z",
          "start_time": "2020-09-17T19:00:45.175755Z"
        },
        "id": "akVtOtkAcIhx"
      },
      "source": [
        "# remove url/website that didn't use http, is only checking for .com websites \n",
        "# so words that are seperated by a . are not removed\n",
        "df_clean.pretweet = df_clean.pretweet.apply(lambda x: re.sub(r\"www\\.[a-z]?\\.?(com)+|[a-z]+\\.(com)\", '', x))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:45.298822Z",
          "start_time": "2020-09-17T19:00:45.274440Z"
        },
        "id": "keyhE6N0cIhy"
      },
      "source": [
        "# remove @mention\n",
        "df_clean.pretweet = df_clean.pretweet.apply(lambda x: re.sub(r'@mention', '', x))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:45.325421Z",
          "start_time": "2020-09-17T19:00:45.301103Z"
        },
        "id": "N7jO9W-YcIhz"
      },
      "source": [
        "# remove {link}\n",
        "df_clean.pretweet = df_clean.pretweet.apply(lambda x: re.sub(r'{link}', '', x))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:45.350693Z",
          "start_time": "2020-09-17T19:00:45.327673Z"
        },
        "id": "kN4wkK9OcIh1"
      },
      "source": [
        "# remove &text; html chars\n",
        "df_clean.pretweet = df_clean.pretweet.apply(lambda x: re.sub(r'&[a-z]+;', '', x))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:45.375633Z",
          "start_time": "2020-09-17T19:00:45.353049Z"
        },
        "id": "zrXBFX7HcIh2"
      },
      "source": [
        "# [video]\n",
        "df_clean.pretweet = df_clean.pretweet.apply(lambda x: re.sub(r\"\\[video\\]\", '', x))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:45.423498Z",
          "start_time": "2020-09-17T19:00:45.377845Z"
        },
        "id": "-lA0DVBAcIh2"
      },
      "source": [
        "# remove all remaining characters that aren't letters, white space, or \n",
        "# the following #:)(/\\='] that are used in emojis or hashtags\n",
        "df_clean.pretweet = df_clean.pretweet.apply(lambda x: re.sub(r\"[^a-z\\s\\(\\-:\\)\\\\\\/\\];='#]\", '', x))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:45.438409Z",
          "start_time": "2020-09-17T19:00:45.425738Z"
        },
        "id": "ALtW4onHcIh3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "outputId": "4c669fb3-2dc9-4c46-be49-5565f28a4b3e"
      },
      "source": [
        "df_clean.iloc[90:100]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>location</th>\n",
              "      <th>pretweet</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>Are you joining me to vote for @NAkufoAddo on 7th Dec?\\n#1Touch4Nana #4MoreForNana\\n#AppreciateAkufoAddo https://t.co/9zcefdXQyW</td>\n",
              "      <td>Kwahu Bepong</td>\n",
              "      <td>are you join vote for th dec touchnana morefornana appreciateakufoaddo</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>@ObreAkye @NAkufoAddo I'm sure the police will be given electronic devices for that purpose.</td>\n",
              "      <td>Tema, Ghana</td>\n",
              "      <td>im sure the polic will given electron devic for that purpos</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>@JuliusOkpei @NAkufoAddo So because heÃ¢â¬â¢s using the countries revenue to benefit us we canÃ¢â¬â¢t appreciate him erhhhh??Ã¢â¬Â¦ https://t.co/kOcWTCT4dJ</td>\n",
              "      <td>NaN</td>\n",
              "      <td>becaus he use the countri revenu benefit cant appreci him erhhhh</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>@luielle @iamAmaBlue @NAkufoAddo Then go there</td>\n",
              "      <td>Tema, Ghana</td>\n",
              "      <td>then there</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>@ShopAuthenticGh @Bra_Sammy20 @AbbanyawYaw @NAkufoAddo Increase the volume bro</td>\n",
              "      <td>Ghana</td>\n",
              "      <td>increas the volum bro</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>@alffyalf1 @__mbrownn @AgnesAdjei10 @gisthaphy @NAkufoAddo @O_LI_SE Hey enough of this ok. One love</td>\n",
              "      <td>Lagos, Nigeria</td>\n",
              "      <td>hey enough thi ok one love</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>@shattadrake @flexkgermain @NAkufoAddo US sef dey owe, make we think</td>\n",
              "      <td>NaN</td>\n",
              "      <td>sef dey owe make think</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>Where is that stupid boy @kwadwosheldon masa u must apologize to our Great President @NAkufoAddo</td>\n",
              "      <td>Sunyani, Ghana</td>\n",
              "      <td>where that stupid boy masa must apolog our great presid</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>@Eli_elShay @RexOmarrr @NAkufoAddo ThatÃ¢â¬â¢s wat u seeing</td>\n",
              "      <td>Ghana</td>\n",
              "      <td>that wat see</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>Please President @NAkufoAddo can you employ him in the fire service...he's saved many live at the collapsed churchÃ¢â¬Â¦ https://t.co/HnHiSG6rhP</td>\n",
              "      <td>Greater Kumasi, Ghana.</td>\n",
              "      <td>pleas presid can you employ him the fire serviceh save mani live the collaps church</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                               tweet  ... Sentiment\n",
              "90                                  Are you joining me to vote for @NAkufoAddo on 7th Dec?\\n#1Touch4Nana #4MoreForNana\\n#AppreciateAkufoAddo https://t.co/9zcefdXQyW  ...       1.0\n",
              "91                                                                      @ObreAkye @NAkufoAddo I'm sure the police will be given electronic devices for that purpose.  ...       0.0\n",
              "92  @JuliusOkpei @NAkufoAddo So because heÃ¢â¬â¢s using the countries revenue to benefit us we canÃ¢â¬â¢t appreciate him erhhhh??Ã¢â¬Â¦ https://t.co/kOcWTCT4dJ  ...       0.0\n",
              "93                                                                                                                    @luielle @iamAmaBlue @NAkufoAddo Then go there  ...       0.0\n",
              "94                                                                                    @ShopAuthenticGh @Bra_Sammy20 @AbbanyawYaw @NAkufoAddo Increase the volume bro  ...       0.0\n",
              "95                                                               @alffyalf1 @__mbrownn @AgnesAdjei10 @gisthaphy @NAkufoAddo @O_LI_SE Hey enough of this ok. One love  ...       0.0\n",
              "96                                                                                              @shattadrake @flexkgermain @NAkufoAddo US sef dey owe, make we think  ...       0.0\n",
              "97                                                                  Where is that stupid boy @kwadwosheldon masa u must apologize to our Great President @NAkufoAddo  ...       0.0\n",
              "98                                                                                                     @Eli_elShay @RexOmarrr @NAkufoAddo ThatÃ¢â¬â¢s wat u seeing  ...       0.0\n",
              "99                 Please President @NAkufoAddo can you employ him in the fire service...he's saved many live at the collapsed churchÃ¢â¬Â¦ https://t.co/HnHiSG6rhP  ...       0.0\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqC7J5MucIh5"
      },
      "source": [
        "# Tokenize pretweet\n",
        "\n",
        "Use the specialized NLTK TweetTokenizer to keep hashtags and emojis "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:45.444339Z",
          "start_time": "2020-09-17T19:00:45.440560Z"
        },
        "id": "1U9xdJEvcIh7"
      },
      "source": [
        "tknzr = TweetTokenizer()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:46.243467Z",
          "start_time": "2020-09-17T19:00:45.446780Z"
        },
        "id": "4-ZijP9kcIh8"
      },
      "source": [
        "df_clean['tokens'] = df_clean['pretweet'].apply(tknzr.tokenize)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:46.265493Z",
          "start_time": "2020-09-17T19:00:46.245711Z"
        },
        "id": "9h_aBSDUcIh9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "8f75d9d4-0a42-46aa-ca2f-b62732a96957"
      },
      "source": [
        "df_clean.iloc[40:50][['pretweet', 'tokens']]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pretweet</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>got sens like that</td>\n",
              "      <td>[got, sens, like, that]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>hmm ghanaian are the caus</td>\n",
              "      <td>[hmm, ghanaian, are, the, caus]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>you are nigerian pleas stay and fight end sar</td>\n",
              "      <td>[you, are, nigerian, pleas, stay, and, fight, end, sar]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>excel your excel</td>\n",
              "      <td>[excel, your, excel]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>ye but where your evid that they didnt their job or</td>\n",
              "      <td>[ye, but, where, your, evid, that, they, didnt, their, job, or]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>wa onli you that benefit from hi free thing but not those need help abandon</td>\n",
              "      <td>[wa, onli, you, that, benefit, from, hi, free, thing, but, not, those, need, help, abandon]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>had hand thi digit transform alway</td>\n",
              "      <td>[had, hand, thi, digit, transform, alway]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>npp campaign your stronghold swing state oo dun let voltarian wast your campaign time yoo</td>\n",
              "      <td>[npp, campaign, your, stronghold, swing, state, oo, dun, let, voltarian, wast, your, campaign, time, yoo]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>the law work tho thi collaps show some evid structur defect</td>\n",
              "      <td>[the, law, work, tho, thi, collaps, show, some, evid, structur, defect]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>oy guy rough nana addo more more</td>\n",
              "      <td>[oy, guy, rough, nana, addo, more, more]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                     pretweet                                                                                                     tokens\n",
              "40                                                                         got sens like that                                                                                    [got, sens, like, that]\n",
              "41                                                                  hmm ghanaian are the caus                                                                            [hmm, ghanaian, are, the, caus]\n",
              "42                                              you are nigerian pleas stay and fight end sar                                                    [you, are, nigerian, pleas, stay, and, fight, end, sar]\n",
              "43                                                                           excel your excel                                                                                       [excel, your, excel]\n",
              "44                                        ye but where your evid that they didnt their job or                                            [ye, but, where, your, evid, that, they, didnt, their, job, or]\n",
              "45                wa onli you that benefit from hi free thing but not those need help abandon                [wa, onli, you, that, benefit, from, hi, free, thing, but, not, those, need, help, abandon]\n",
              "46                                                         had hand thi digit transform alway                                                                  [had, hand, thi, digit, transform, alway]\n",
              "47  npp campaign your stronghold swing state oo dun let voltarian wast your campaign time yoo  [npp, campaign, your, stronghold, swing, state, oo, dun, let, voltarian, wast, your, campaign, time, yoo]\n",
              "48                                the law work tho thi collaps show some evid structur defect                                    [the, law, work, tho, thi, collaps, show, some, evid, structur, defect]\n",
              "49                                                           oy guy rough nana addo more more                                                                   [oy, guy, rough, nana, addo, more, more]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSr355UgcIh-"
      },
      "source": [
        "## Remove Punctuation From Tokens\n",
        "\n",
        "The tweet tokenizer combined characters that make common emoticons, but all the other punctuation needs to be removed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:46.270925Z",
          "start_time": "2020-09-17T19:00:46.267650Z"
        },
        "id": "z1ti6ljgcIh_"
      },
      "source": [
        "PUNCUATION_LIST = list(string.punctuation)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:46.286398Z",
          "start_time": "2020-09-17T19:00:46.273121Z"
        },
        "id": "gapNc9YlcIiA"
      },
      "source": [
        "def remove_punctuation(word_list):\n",
        "    \"\"\"Remove punctuation tokens from a list of tokens\"\"\"\n",
        "    return [w for w in word_list if w not in PUNCUATION_LIST]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:46.398590Z",
          "start_time": "2020-09-17T19:00:46.288674Z"
        },
        "id": "alYJO_fecIiB"
      },
      "source": [
        "df_clean['tokens'] = df_clean['tokens'].apply(remove_punctuation)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDJouUNIcIiC"
      },
      "source": [
        "# Create Corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:52.513618Z",
          "start_time": "2020-09-17T19:00:46.400844Z"
        },
        "id": "ixmmSOCwcIiC"
      },
      "source": [
        "corpus_tokens = df_clean['tokens'].sum()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dyAUYN5cIiD"
      },
      "source": [
        "# Check Frequency Distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:52.717610Z",
          "start_time": "2020-09-17T19:00:52.515937Z"
        },
        "id": "Ia8QljkucIiE"
      },
      "source": [
        "corpus_freq_dist = FreqDist(corpus_tokens)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:52.729319Z",
          "start_time": "2020-09-17T19:00:52.724627Z"
        },
        "id": "Ks0OMDShcIiF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9ee1221-a5d2-47d2-b309-46398c84a48d"
      },
      "source": [
        "len(corpus_freq_dist)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5622"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEwdhSlGcIiG"
      },
      "source": [
        "How many words appear only once?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:52.750450Z",
          "start_time": "2020-09-17T19:00:52.733523Z"
        },
        "id": "qhUm8-OgcIiG"
      },
      "source": [
        "only_one_instance = [w for w in corpus_freq_dist.most_common() if w[1] == 1]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:52.763457Z",
          "start_time": "2020-09-17T19:00:52.752537Z"
        },
        "id": "cl_viit6cIiJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d63f87a-f783-428f-9e52-d0bced5cf041"
      },
      "source": [
        "len(only_one_instance)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3013"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRCuF9l_cIiK"
      },
      "source": [
        "More than half of the words in the corpus appear only once."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xK-rmrnscIiL"
      },
      "source": [
        "How many words appear at least 5 times?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:52.777873Z",
          "start_time": "2020-09-17T19:00:52.765755Z"
        },
        "id": "XW9_J7UTcIiM"
      },
      "source": [
        "at_least_five = [w for w in corpus_freq_dist.most_common() if w[1] >= 5]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:52.785448Z",
          "start_time": "2020-09-17T19:00:52.780131Z"
        },
        "id": "YMXUG7wKcIiN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c316bffd-1fd0-4de3-9ac7-e3677785deef"
      },
      "source": [
        "len(at_least_five)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1231"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:52.796423Z",
          "start_time": "2020-09-17T19:00:52.787906Z"
        },
        "scrolled": true,
        "id": "ywqT_FqRcIiO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bab840d-0c3d-488b-fcf2-0bbfeadf9eb2"
      },
      "source": [
        "at_least_five[:50]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 2159),\n",
              " ('you', 1585),\n",
              " ('and', 1015),\n",
              " ('for', 806),\n",
              " ('your', 607),\n",
              " ('are', 581),\n",
              " ('thi', 558),\n",
              " ('presid', 527),\n",
              " ('that', 513),\n",
              " ('ghana', 381),\n",
              " ('not', 345),\n",
              " ('will', 337),\n",
              " ('what', 334),\n",
              " ('have', 328),\n",
              " ('elect', 303),\n",
              " ('with', 276),\n",
              " ('they', 273),\n",
              " ('peopl', 272),\n",
              " ('all', 270),\n",
              " ('congratul', 263),\n",
              " ('dont', 260),\n",
              " ('but', 234),\n",
              " ('hi', 222),\n",
              " ('pleas', 221),\n",
              " ('more', 217),\n",
              " ('our', 213),\n",
              " ('nana', 204),\n",
              " ('wa', 202),\n",
              " ('it', 202),\n",
              " ('ha', 201),\n",
              " ('vote', 201),\n",
              " ('can', 193),\n",
              " ('who', 181),\n",
              " ('know', 174),\n",
              " ('god', 173),\n",
              " ('from', 173),\n",
              " ('one', 166),\n",
              " ('how', 162),\n",
              " ('like', 161),\n",
              " ('ghanaian', 156),\n",
              " ('job', 154),\n",
              " ('see', 153),\n",
              " ('say', 147),\n",
              " ('whi', 147),\n",
              " ('about', 143),\n",
              " ('good', 138),\n",
              " ('just', 138),\n",
              " ('him', 137),\n",
              " ('come', 137),\n",
              " ('npp', 136)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yplBLNiKcIiP"
      },
      "source": [
        "This group is more than one fifth of the corpus and contains many stop words that would typically be removed from text, however since a tweet is highly restricted to a number of characters, each word that a person uses is of potential value for the sentiment analysis.  \n",
        "\n",
        "Additionally, According to a study down on the removal of stop words from tweets when doing sentiment analysis, removing them degrades classification performance. see [link](https://www.aclweb.org/anthology/L14-1265/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wyIOODhcIiQ"
      },
      "source": [
        "# Save Cleaned and Tokenized Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:52.804231Z",
          "start_time": "2020-09-17T19:00:52.798611Z"
        },
        "id": "fk6Z4AuGcIiQ"
      },
      "source": [
        "if SAVE_FILE:\n",
        "    df_clean.to_csv(DATA_FILE_PATH + TOKENIZED_DATA_FILE_NAME, index=False)"
      ],
      "execution_count": 30,
      "outputs": []
    }
  ]
}