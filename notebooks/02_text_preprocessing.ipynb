{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "learn-env",
      "language": "python",
      "name": "learn-env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "02_text_preprocessing.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShesterG/Twitter-Sentiment-Analysis/blob/master/notebooks/02_text_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWj_6vRQcIhQ"
      },
      "source": [
        "# Text Preprocessing for Twitter Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQTwCck2y55n",
        "outputId": "75b7f800-6e4f-4cf8-a196-81ccbb9e2a03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-W9yM2YCcIhd"
      },
      "source": [
        "# Imports and Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:45.050110Z",
          "start_time": "2020-09-17T19:00:43.770359Z"
        },
        "id": "fzxCSJvicIhf"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk import FreqDist\n",
        "import string"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:45.056796Z",
          "start_time": "2020-09-17T19:00:45.052662Z"
        },
        "id": "hzjNrkwfcIhi"
      },
      "source": [
        "DATA_FILE_PATH = '/content/drive/MyDrive/NLPGh/'\n",
        "CLEAN_DATA_FILE_NAME = 'DataSet2Clean.csv'\n",
        "SAVE_FILE = True\n",
        "TOKENIZED_DATA_FILE_NAME = 'DataSet2Tokenized.csv'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xW_HYH7cIhj"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:45.092191Z",
          "start_time": "2020-09-17T19:00:45.059527Z"
        },
        "id": "Hb-WRYrVcIhk"
      },
      "source": [
        "df = pd.read_csv(DATA_FILE_PATH + CLEAN_DATA_FILE_NAME)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:45.122879Z",
          "start_time": "2020-09-17T19:00:45.094914Z"
        },
        "id": "jvv1nUCEcIhm",
        "outputId": "01bd2358-ff81-445a-8dca-13896fc785ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "pd.set_option('display.max_colwidth', None)\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed</th>\n",
              "      <th>tweet</th>\n",
              "      <th>location</th>\n",
              "      <th>pretweet</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>65780</td>\n",
              "      <td>Pls add us some momo to make data  0246964913 ðŸ˜‚ðŸ˜‚ðŸ˜‚ https://t.co/w5ozYUF59x</td>\n",
              "      <td>NaN</td>\n",
              "      <td>pl add some momo make data 0246964913</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>65781</td>\n",
              "      <td>@McVan_1 @AnnanPerry @blac4rina We will descend on @NAkufoAddo soon</td>\n",
              "      <td>Ghana</td>\n",
              "      <td>will descend soon</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65782</td>\n",
              "      <td>*Forgery allegations by EC is not enough to disqualify the five presidential candidates*\\n\\nhttps://t.co/GAkYghEbQHâ€¦ https://t.co/o0pCodbuWj</td>\n",
              "      <td>NaN</td>\n",
              "      <td>forgeri alleg not enough disqualifi the five presidenti candid</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>65783</td>\n",
              "      <td>@NiiWills @bosompemny I donâ€™t know how dem dey see @NAkufoAddo oo</td>\n",
              "      <td>dansoman accra</td>\n",
              "      <td>dont know how dem dey see</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>65784</td>\n",
              "      <td>Do we have online renewal what what ka kwano?? https://t.co/3CdekJYMgr</td>\n",
              "      <td>Botswana</td>\n",
              "      <td>have onlin renew what what kwano</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed  ... Sentiment\n",
              "0    65780  ...       0.0\n",
              "1    65781  ...       0.0\n",
              "2    65782  ...       0.0\n",
              "3    65783  ...       0.0\n",
              "4    65784  ...       0.0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXRpiseEcIhr"
      },
      "source": [
        "# Clean Tweet Text Data\n",
        "\n",
        "* Change all text to lowercase\n",
        "* Remove urls\n",
        "* Remove mentions\n",
        "* Remove placeholders {link} and \\[video\\]\n",
        "* Remove punctuation that isn't associated with emojis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:45.128513Z",
          "start_time": "2020-09-17T19:00:45.125151Z"
        },
        "id": "Rc6diSeQcIht"
      },
      "source": [
        "df_clean = df"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:45.147025Z",
          "start_time": "2020-09-17T19:00:45.130693Z"
        },
        "id": "pQAyc1RWcIhv"
      },
      "source": [
        "# lower case\n",
        "df_clean.pretweet = df_clean.pretweet.str.lower()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:45.171568Z",
          "start_time": "2020-09-17T19:00:45.149325Z"
        },
        "id": "HuFn_BfYcIhw"
      },
      "source": [
        "# remove url links\n",
        "df_clean.pretweet = df_clean.pretweet.apply(lambda x: re.sub(r'https?:\\/\\/\\S+', '', x))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:45.271491Z",
          "start_time": "2020-09-17T19:00:45.175755Z"
        },
        "id": "akVtOtkAcIhx"
      },
      "source": [
        "# remove url/website that didn't use http, is only checking for .com websites \n",
        "# so words that are seperated by a . are not removed\n",
        "df_clean.pretweet = df_clean.pretweet.apply(lambda x: re.sub(r\"www\\.[a-z]?\\.?(com)+|[a-z]+\\.(com)\", '', x))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:45.298822Z",
          "start_time": "2020-09-17T19:00:45.274440Z"
        },
        "id": "keyhE6N0cIhy"
      },
      "source": [
        "# remove @mention\n",
        "df_clean.pretweet = df_clean.pretweet.apply(lambda x: re.sub(r'@mention', '', x))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:45.325421Z",
          "start_time": "2020-09-17T19:00:45.301103Z"
        },
        "id": "N7jO9W-YcIhz"
      },
      "source": [
        "# remove {link}\n",
        "df_clean.pretweet = df_clean.pretweet.apply(lambda x: re.sub(r'{link}', '', x))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:45.350693Z",
          "start_time": "2020-09-17T19:00:45.327673Z"
        },
        "id": "kN4wkK9OcIh1"
      },
      "source": [
        "# remove &text; html chars\n",
        "df_clean.pretweet = df_clean.pretweet.apply(lambda x: re.sub(r'&[a-z]+;', '', x))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:45.375633Z",
          "start_time": "2020-09-17T19:00:45.353049Z"
        },
        "id": "zrXBFX7HcIh2"
      },
      "source": [
        "# [video]\n",
        "df_clean.pretweet = df_clean.pretweet.apply(lambda x: re.sub(r\"\\[video\\]\", '', x))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:45.423498Z",
          "start_time": "2020-09-17T19:00:45.377845Z"
        },
        "id": "-lA0DVBAcIh2"
      },
      "source": [
        "# remove all remaining characters that aren't letters, white space, or \n",
        "# the following #:)(/\\='] that are used in emojis or hashtags\n",
        "df_clean.pretweet = df_clean.pretweet.apply(lambda x: re.sub(r\"[^a-z\\s\\(\\-:\\)\\\\\\/\\];='#]\", '', x))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:45.438409Z",
          "start_time": "2020-09-17T19:00:45.425738Z"
        },
        "id": "ALtW4onHcIh3",
        "outputId": "42076e0d-4aa3-40a5-a7e4-eaacae4b9075",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        }
      },
      "source": [
        "df_clean.iloc[90:100]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed</th>\n",
              "      <th>tweet</th>\n",
              "      <th>location</th>\n",
              "      <th>pretweet</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>65885</td>\n",
              "      <td>Are you joining me to vote for @NAkufoAddo on 7th Dec?\\n#1Touch4Nana #4MoreForNana\\n#AppreciateAkufoAddo https://t.co/9zcefdXQyW</td>\n",
              "      <td>Kwahu Bepong</td>\n",
              "      <td>are you join vote for th dec touchnana morefornana appreciateakufoaddo</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>65887</td>\n",
              "      <td>@ObreAkye @NAkufoAddo I'm sure the police will be given electronic devices for that purpose.</td>\n",
              "      <td>Tema, Ghana</td>\n",
              "      <td>im sure the polic will given electron devic for that purpos</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>65888</td>\n",
              "      <td>@JuliusOkpei @NAkufoAddo So because heâ€™s using the countries revenue to benefit us we canâ€™t appreciate him erhhhh??â€¦ https://t.co/kOcWTCT4dJ</td>\n",
              "      <td>NaN</td>\n",
              "      <td>becaus he use the countri revenu benefit cant appreci him erhhhh</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>65889</td>\n",
              "      <td>@luielle @iamAmaBlue @NAkufoAddo Then go there</td>\n",
              "      <td>Tema, Ghana</td>\n",
              "      <td>then there</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>65891</td>\n",
              "      <td>@ShopAuthenticGh @Bra_Sammy20 @AbbanyawYaw @NAkufoAddo Increase the volume bro</td>\n",
              "      <td>Ghana</td>\n",
              "      <td>increas the volum bro</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>65892</td>\n",
              "      <td>@alffyalf1 @__mbrownn @AgnesAdjei10 @gisthaphy @NAkufoAddo @O_LI_SE Hey enough of this ok. One love</td>\n",
              "      <td>Lagos, Nigeria</td>\n",
              "      <td>hey enough thi ok one love</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>65893</td>\n",
              "      <td>@shattadrake @flexkgermain @NAkufoAddo US sef dey owe, make we think</td>\n",
              "      <td>NaN</td>\n",
              "      <td>sef dey owe make think</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>65894</td>\n",
              "      <td>Where is that stupid boy @kwadwosheldon masa u must apologize to our Great President @NAkufoAddo</td>\n",
              "      <td>Sunyani, Ghana</td>\n",
              "      <td>where that stupid boy masa must apolog our great presid</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>65895</td>\n",
              "      <td>@Eli_elShay @RexOmarrr @NAkufoAddo Thatâ€™s wat u seeing</td>\n",
              "      <td>Ghana</td>\n",
              "      <td>that wat see</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>65896</td>\n",
              "      <td>Please President @NAkufoAddo can you employ him in the fire service...he's saved many live at the collapsed churchâ€¦ https://t.co/HnHiSG6rhP</td>\n",
              "      <td>Greater Kumasi, Ghana.</td>\n",
              "      <td>pleas presid can you employ him the fire serviceh save mani live the collaps church</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Unnamed  ... Sentiment\n",
              "90    65885  ...       1.0\n",
              "91    65887  ...       0.0\n",
              "92    65888  ...       0.0\n",
              "93    65889  ...       0.0\n",
              "94    65891  ...       0.0\n",
              "95    65892  ...       0.0\n",
              "96    65893  ...       0.0\n",
              "97    65894  ...       0.0\n",
              "98    65895  ...       0.0\n",
              "99    65896  ...       0.0\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqC7J5MucIh5"
      },
      "source": [
        "# Tokenize pretweet\n",
        "\n",
        "Use the specialized NLTK TweetTokenizer to keep hashtags and emojis "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:45.444339Z",
          "start_time": "2020-09-17T19:00:45.440560Z"
        },
        "id": "1U9xdJEvcIh7"
      },
      "source": [
        "tknzr = TweetTokenizer()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:46.243467Z",
          "start_time": "2020-09-17T19:00:45.446780Z"
        },
        "id": "4-ZijP9kcIh8"
      },
      "source": [
        "df_clean['tokens'] = df_clean['pretweet'].apply(tknzr.tokenize)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:46.265493Z",
          "start_time": "2020-09-17T19:00:46.245711Z"
        },
        "id": "9h_aBSDUcIh9",
        "outputId": "ea2e29f3-8f3d-4708-f8a9-9c600b1931cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        }
      },
      "source": [
        "df_clean.iloc[40:50][['pretweet', 'tokens']]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pretweet</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>got sens like that</td>\n",
              "      <td>[got, sens, like, that]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>hmm ghanaian are the caus</td>\n",
              "      <td>[hmm, ghanaian, are, the, caus]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>you are nigerian pleas stay and fight end sar</td>\n",
              "      <td>[you, are, nigerian, pleas, stay, and, fight, end, sar]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>excel your excel</td>\n",
              "      <td>[excel, your, excel]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>ye but where your evid that they didnt their job or</td>\n",
              "      <td>[ye, but, where, your, evid, that, they, didnt, their, job, or]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>wa onli you that benefit from hi free thing but not those need help abandon</td>\n",
              "      <td>[wa, onli, you, that, benefit, from, hi, free, thing, but, not, those, need, help, abandon]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>had hand thi digit transform alway</td>\n",
              "      <td>[had, hand, thi, digit, transform, alway]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>npp campaign your stronghold swing state oo dun let voltarian wast your campaign time yoo</td>\n",
              "      <td>[npp, campaign, your, stronghold, swing, state, oo, dun, let, voltarian, wast, your, campaign, time, yoo]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>the law work tho thi collaps show some evid structur defect</td>\n",
              "      <td>[the, law, work, tho, thi, collaps, show, some, evid, structur, defect]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>oy guy rough nana addo more more</td>\n",
              "      <td>[oy, guy, rough, nana, addo, more, more]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                     pretweet                                                                                                     tokens\n",
              "40                                                                         got sens like that                                                                                    [got, sens, like, that]\n",
              "41                                                                  hmm ghanaian are the caus                                                                            [hmm, ghanaian, are, the, caus]\n",
              "42                                              you are nigerian pleas stay and fight end sar                                                    [you, are, nigerian, pleas, stay, and, fight, end, sar]\n",
              "43                                                                           excel your excel                                                                                       [excel, your, excel]\n",
              "44                                        ye but where your evid that they didnt their job or                                            [ye, but, where, your, evid, that, they, didnt, their, job, or]\n",
              "45                wa onli you that benefit from hi free thing but not those need help abandon                [wa, onli, you, that, benefit, from, hi, free, thing, but, not, those, need, help, abandon]\n",
              "46                                                         had hand thi digit transform alway                                                                  [had, hand, thi, digit, transform, alway]\n",
              "47  npp campaign your stronghold swing state oo dun let voltarian wast your campaign time yoo  [npp, campaign, your, stronghold, swing, state, oo, dun, let, voltarian, wast, your, campaign, time, yoo]\n",
              "48                                the law work tho thi collaps show some evid structur defect                                    [the, law, work, tho, thi, collaps, show, some, evid, structur, defect]\n",
              "49                                                           oy guy rough nana addo more more                                                                   [oy, guy, rough, nana, addo, more, more]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSr355UgcIh-"
      },
      "source": [
        "## Remove Punctuation From Tokens\n",
        "\n",
        "The tweet tokenizer combined characters that make common emoticons, but all the other punctuation needs to be removed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:46.270925Z",
          "start_time": "2020-09-17T19:00:46.267650Z"
        },
        "id": "z1ti6ljgcIh_"
      },
      "source": [
        "PUNCUATION_LIST = list(string.punctuation)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:46.286398Z",
          "start_time": "2020-09-17T19:00:46.273121Z"
        },
        "id": "gapNc9YlcIiA"
      },
      "source": [
        "def remove_punctuation(word_list):\n",
        "    \"\"\"Remove punctuation tokens from a list of tokens\"\"\"\n",
        "    return [w for w in word_list if w not in PUNCUATION_LIST]"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:46.398590Z",
          "start_time": "2020-09-17T19:00:46.288674Z"
        },
        "id": "alYJO_fecIiB"
      },
      "source": [
        "df_clean['tokens'] = df_clean['tokens'].apply(remove_punctuation)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDJouUNIcIiC"
      },
      "source": [
        "# Create Corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:52.513618Z",
          "start_time": "2020-09-17T19:00:46.400844Z"
        },
        "id": "ixmmSOCwcIiC"
      },
      "source": [
        "corpus_tokens = df_clean['tokens'].sum()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dyAUYN5cIiD"
      },
      "source": [
        "# Check Frequency Distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:52.717610Z",
          "start_time": "2020-09-17T19:00:52.515937Z"
        },
        "id": "Ia8QljkucIiE"
      },
      "source": [
        "corpus_freq_dist = FreqDist(corpus_tokens)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:52.729319Z",
          "start_time": "2020-09-17T19:00:52.724627Z"
        },
        "id": "Ks0OMDShcIiF",
        "outputId": "807139e2-94b8-4fdd-e698-9b22e9aeb7a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(corpus_freq_dist)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3347"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEwdhSlGcIiG"
      },
      "source": [
        "How many words appear only once?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:52.750450Z",
          "start_time": "2020-09-17T19:00:52.733523Z"
        },
        "id": "qhUm8-OgcIiG"
      },
      "source": [
        "only_one_instance = [w for w in corpus_freq_dist.most_common() if w[1] == 1]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:52.763457Z",
          "start_time": "2020-09-17T19:00:52.752537Z"
        },
        "id": "cl_viit6cIiJ",
        "outputId": "6e391867-29b5-4e1c-ca38-51d25f367710",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(only_one_instance)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1805"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRCuF9l_cIiK"
      },
      "source": [
        "More than half of the words in the corpus appear only once."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xK-rmrnscIiL"
      },
      "source": [
        "How many words appear at least 5 times?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:52.777873Z",
          "start_time": "2020-09-17T19:00:52.765755Z"
        },
        "id": "XW9_J7UTcIiM"
      },
      "source": [
        "at_least_five = [w for w in corpus_freq_dist.most_common() if w[1] >= 5]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:52.785448Z",
          "start_time": "2020-09-17T19:00:52.780131Z"
        },
        "id": "YMXUG7wKcIiN",
        "outputId": "dceff6c2-45dc-4e14-a2b4-89b712a61a1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(at_least_five)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "651"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:52.796423Z",
          "start_time": "2020-09-17T19:00:52.787906Z"
        },
        "scrolled": true,
        "id": "ywqT_FqRcIiO",
        "outputId": "6809f001-9d41-4aef-bf13-901ad5270466",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "at_least_five[:50]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 815),\n",
              " ('you', 581),\n",
              " ('and', 399),\n",
              " ('for', 370),\n",
              " ('thi', 268),\n",
              " ('are', 264),\n",
              " ('that', 208),\n",
              " ('presid', 198),\n",
              " ('your', 194),\n",
              " ('have', 149),\n",
              " ('what', 149),\n",
              " ('ghana', 145),\n",
              " ('will', 144),\n",
              " ('job', 139),\n",
              " ('not', 135),\n",
              " ('more', 128),\n",
              " ('they', 125),\n",
              " ('dont', 118),\n",
              " ('with', 116),\n",
              " ('all', 111),\n",
              " ('nana', 106),\n",
              " ('but', 99),\n",
              " ('peopl', 97),\n",
              " ('vote', 91),\n",
              " ('our', 90),\n",
              " ('how', 86),\n",
              " ('ha', 85),\n",
              " ('pleas', 84),\n",
              " ('it', 79),\n",
              " ('know', 78),\n",
              " ('can', 78),\n",
              " ('govern', 75),\n",
              " ('come', 74),\n",
              " ('about', 72),\n",
              " ('maintainnanaaddo', 71),\n",
              " ('one', 68),\n",
              " ('wa', 67),\n",
              " ('touchnana', 67),\n",
              " ('see', 64),\n",
              " ('ghanaian', 64),\n",
              " ('make', 62),\n",
              " ('now', 62),\n",
              " ('who', 61),\n",
              " ('say', 61),\n",
              " ('like', 61),\n",
              " ('from', 61),\n",
              " ('hi', 60),\n",
              " ('good', 59),\n",
              " ('dey', 57),\n",
              " ('them', 56)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yplBLNiKcIiP"
      },
      "source": [
        "This group is more than one fifth of the corpus and contains many stop words that would typically be removed from text, however since a tweet is highly restricted to a number of characters, each word that a person uses is of potential value for the sentiment analysis.  \n",
        "\n",
        "Additionally, According to a study down on the removal of stop words from tweets when doing sentiment analysis, removing them degrades classification performance. see [link](https://www.aclweb.org/anthology/L14-1265/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wyIOODhcIiQ"
      },
      "source": [
        "# Save Cleaned and Tokenized Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-17T19:00:52.804231Z",
          "start_time": "2020-09-17T19:00:52.798611Z"
        },
        "id": "fk6Z4AuGcIiQ"
      },
      "source": [
        "if SAVE_FILE:\n",
        "    df_clean.to_csv(DATA_FILE_PATH + TOKENIZED_DATA_FILE_NAME, index=False)"
      ],
      "execution_count": 31,
      "outputs": []
    }
  ]
}