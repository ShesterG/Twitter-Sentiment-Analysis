{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "learn-env",
      "language": "python",
      "name": "learn-env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "12_smv_model_02.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShesterG/Twitter-Sentiment-Analysis/blob/master/notebooks/12_smv_model_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOr84TwcKomO"
      },
      "source": [
        "# SVM with Smote Model for Twitter Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGZkKVLpKomi"
      },
      "source": [
        "This model will use SVM with tf/idf to classify the tweets.\n",
        "\n",
        "It will reduce the dimensionality of the feature set by adjusting the minimum document frequency of words, in an attempt to get better results.\n",
        "\n",
        "It will use SMOTE to synthesize some data to balance the classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MftFUf1Ltx-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d67ef35-8ec5-4396-d58b-2525ffb5e00b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-q54ki6Komk"
      },
      "source": [
        "# Imports and Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-10T17:33:58.632607Z",
          "start_time": "2020-09-10T17:33:57.317553Z"
        },
        "id": "XOkxSJpcKomk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8220c435-5e48-4ca9-d494-a5f1a3f25bd9"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, plot_confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "#import evaluation_functions\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline\n",
        "import ast\n",
        "\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import cross_val_predict\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-10T17:33:58.639394Z",
          "start_time": "2020-09-10T17:33:58.635233Z"
        },
        "id": "XjDfZZQvKomm"
      },
      "source": [
        "DATA_FILE_PATH = '/content/drive/MyDrive/NLPGh/'\n",
        "CLEAN_DATA_FILE_NAME = 'Book6Clean.csv'\n",
        "TOKENIZED_DATA_FILE_NAME = 'Book6Tokenized.csv'\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "RANDOM_STATE = 42"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8p6TU0dHKomn"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-10T17:33:58.693585Z",
          "start_time": "2020-09-10T17:33:58.642232Z"
        },
        "id": "e7HwLTwRKomn"
      },
      "source": [
        "df = pd.read_csv(DATA_FILE_PATH + TOKENIZED_DATA_FILE_NAME)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-10T17:33:58.716944Z",
          "start_time": "2020-09-10T17:33:58.696032Z"
        },
        "id": "D8GqKiY1Komn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "bcee149b-4e88-4ac3-e534-644531cc6816"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>tweet</th>\n",
              "      <th>location_x</th>\n",
              "      <th>pretweet</th>\n",
              "      <th>candidate</th>\n",
              "      <th>LRPredScore</th>\n",
              "      <th>LRConfi</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Unnamed: 8</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>@NsiaAvena @NAkufoAddo They don't know anything about peace</td>\n",
              "      <td>NaN</td>\n",
              "      <td>they dont know anyth about peac</td>\n",
              "      <td>Nana</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['they', 'dont', 'know', 'anyth', 'about', 'peac']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>@NAkufoAddo  H. E Nana please follow up on this FAKE NEWS, LIES and sue BBC for peddling false information. Hold alÃ¢â¬Â¦ https://t.co/SdwnMsxeUV</td>\n",
              "      <td>NaN</td>\n",
              "      <td>nana pleas follow thi fake new lie and sue bbc for peddl fals inform hold al</td>\n",
              "      <td>Nana</td>\n",
              "      <td>-3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['nana', 'pleas', 'follow', 'thi', 'fake', 'new', 'lie', 'and', 'sue', 'bbc', 'for', 'peddl', 'fals', 'inform', 'hold', 'al']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>@BarrowPresident @NAkufoAddo good to go may God bless an protect you</td>\n",
              "      <td>NaN</td>\n",
              "      <td>good may god bless protect you</td>\n",
              "      <td>Nana</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['good', 'may', 'god', 'bless', 'protect', 'you']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>@ChipsJhay @TruthFreema @AOuattara_PRCI @NAkufoAddo No, you haven't. He's using his freedom of speech as it is. He's covered.</td>\n",
              "      <td>Afamase Akotom, Ghana</td>\n",
              "      <td>no you havent he use hi freedom speech is he cover</td>\n",
              "      <td>Nana</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['no', 'you', 'havent', 'he', 'use', 'hi', 'freedom', 'speech', 'is', 'he', 'cover']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>@IssahGerard @HEgyiri @NAkufoAddo Please who is this and how is he your in law??</td>\n",
              "      <td>NaN</td>\n",
              "      <td>pleas who thi and how your law</td>\n",
              "      <td>Nana</td>\n",
              "      <td>-1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['pleas', 'who', 'thi', 'and', 'how', 'your', 'law']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...                                                                                                                         tokens\n",
              "0           0  ...                                                                             ['they', 'dont', 'know', 'anyth', 'about', 'peac']\n",
              "1           2  ...  ['nana', 'pleas', 'follow', 'thi', 'fake', 'new', 'lie', 'and', 'sue', 'bbc', 'for', 'peddl', 'fals', 'inform', 'hold', 'al']\n",
              "2           4  ...                                                                              ['good', 'may', 'god', 'bless', 'protect', 'you']\n",
              "3           6  ...                                           ['no', 'you', 'havent', 'he', 'use', 'hi', 'freedom', 'speech', 'is', 'he', 'cover']\n",
              "4           7  ...                                                                           ['pleas', 'who', 'thi', 'and', 'how', 'your', 'law']\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUM_HOPy79c9"
      },
      "source": [
        "df = df[df.Sentiment != 0]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-10T17:33:59.158553Z",
          "start_time": "2020-09-10T17:33:58.719183Z"
        },
        "id": "OLfKOp0DKomo"
      },
      "source": [
        "# convert list of strings represented as a string to a list of strings\n",
        "df.tokens = df.tokens.map(ast.literal_eval)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-10T17:33:59.166031Z",
          "start_time": "2020-09-10T17:33:59.160668Z"
        },
        "id": "2-IVZp-qKomp"
      },
      "source": [
        "data = df[['tokens', 'Sentiment']]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-10T17:33:59.181978Z",
          "start_time": "2020-09-10T17:33:59.168323Z"
        },
        "id": "9ot3qehDKomp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0a3de6f6-c218-4610-d241-10068ab40446"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[they, dont, know, anyth, about, peac]</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[good, may, god, bless, protect, you]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[presid, receiv, the, grace, god, almighti, what, ha, ordain, you, for, jesu, mighti, name]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[gad, cant, believ, itu, are, congratul, dem, npp, parti, are, corrupt]</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[pleas, may, god, continu, strengthen, you, more, pleas]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                        tokens  Sentiment\n",
              "0                                                       [they, dont, know, anyth, about, peac]         -1\n",
              "2                                                        [good, may, god, bless, protect, you]          1\n",
              "5  [presid, receiv, the, grace, god, almighti, what, ha, ordain, you, for, jesu, mighti, name]          1\n",
              "6                      [gad, cant, believ, itu, are, congratul, dem, npp, parti, are, corrupt]         -1\n",
              "7                                     [pleas, may, god, continu, strengthen, you, more, pleas]          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XQ1lJ--Komp"
      },
      "source": [
        "# Split Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-10T17:33:59.208403Z",
          "start_time": "2020-09-10T17:33:59.186404Z"
        },
        "id": "LsE-CjGQKomq"
      },
      "source": [
        "\"\"\"\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['tokens'], \n",
        "                                                    data['Sentiment'],\n",
        "                                                   test_size = 0.2,\n",
        "                                                   random_state = RANDOM_STATE,\n",
        "                                                   stratify = data['Sentiment'])\n",
        "\"\"\"  \n",
        "\n",
        "X = data['tokens']\n",
        "y = data['Sentiment']"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-10T17:33:59.217856Z",
          "start_time": "2020-09-10T17:33:59.211816Z"
        },
        "id": "e6ZbJhDpKomq"
      },
      "source": [
        "#X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-10T17:33:59.225303Z",
          "start_time": "2020-09-10T17:33:59.220214Z"
        },
        "id": "LhuTx3bAKomr"
      },
      "source": [
        "#X_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIYUAWJXKomr"
      },
      "source": [
        "# Encode Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-10T17:33:59.231548Z",
          "start_time": "2020-09-10T17:33:59.228153Z"
        },
        "id": "b9h7GJtyKomr"
      },
      "source": [
        "le = LabelEncoder()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-10T17:33:59.239063Z",
          "start_time": "2020-09-10T17:33:59.233579Z"
        },
        "id": "YmS4TDmSKomr"
      },
      "source": [
        "#y_train_enc = le.fit_transform(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-10T17:33:59.255359Z",
          "start_time": "2020-09-10T17:33:59.241210Z"
        },
        "id": "HORAhV0PKoms"
      },
      "source": [
        "#y_test_enc = le.transform(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3ZgICYbkMpH"
      },
      "source": [
        "y_enc = le.fit_transform(y)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bb7VFeaOa8pn"
      },
      "source": [
        "kf = KFold(2000, n_folds=10)\n",
        "\n",
        "accuracy = []\n",
        "fold = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ep11COZQKoms"
      },
      "source": [
        "# Evaluate Adjustments to Minimum Document Frequency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-10T17:33:59.261759Z",
          "start_time": "2020-09-10T17:33:59.257741Z"
        },
        "id": "xgFhcb5OKoms"
      },
      "source": [
        "def passthrough(doc):\n",
        "    \"\"\"passthrough function for use in the pipeline because the text is already tokenized\"\"\"\n",
        "    return doc"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-10T17:33:59.276479Z",
          "start_time": "2020-09-10T17:33:59.264034Z"
        },
        "id": "FAQzIQvpKoms"
      },
      "source": [
        "def train_and_eval_model(min_df):\n",
        "    \"\"\"\n",
        "    Train and Evaluate and Bag of Words Representation with a SVM\n",
        "    classifier with a specified minimum document frequency.\n",
        "    \"\"\"\n",
        "    \n",
        "    pipeline = Pipeline([('bow',CountVectorizer(min_df=min_df, \n",
        "                                                preprocessor=passthrough, \n",
        "                                                tokenizer=passthrough)),\n",
        "                         ('tfidf', TfidfTransformer()),\n",
        "                         ('smote', SMOTE(random_state=RANDOM_STATE, \n",
        "                                         n_jobs=-1)),\n",
        "                         ('SVM', SVC(kernel = 'linear', probability = True, random_state = RANDOM_STATE))\n",
        "                         ])\n",
        "    \n",
        "\n",
        "    #scores = cross_validation.cross_val_score(Pipeline, X_train,y_train_enc, cv=10)\n",
        "    #pipeline.score\n",
        "    scoring = ['accuracy','f1','precision','recall']\n",
        "    scores = cross_validate(pipeline, X, y, cv=10, scoring=scoring)\n",
        "    sorted(scores.keys())\n",
        "\n",
        "\n",
        "    #score_mean = scores.mean()\n",
        "\n",
        "\n",
        "    #pipeline.fit(X_train,y_train_enc)\n",
        "    \n",
        "    print(f'MINIMUM DOCUMENT FREQUENCY = {min_df}')\n",
        "    print('')\n",
        "    \n",
        "    \"\"\"\n",
        "    #y_pred = cross_val_predict(Pipeline, X, Y, cv=10)\n",
        "    \n",
        "    \n",
        "    #y_pred = pipeline.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "    #conf_matrix = confusion_matrix(y_true=y_test_enc, y_pred=y_pred)\n",
        "    #confusion_matrix(y_true=y_train_enc, y_pred=pipeline.predict(X_train),labels='Training')\n",
        "\n",
        "    \n",
        "    #classi_report = classification_report(y_true=y_test_enc, y_pred=y_pred, target_names=['Negative', 'Postive'])\n",
        "    #print(classi_report)\n",
        "    ['fit_time', 'score_time', 'test_prec_macro', 'test_rec_macro',\n",
        " 'train_prec_macro', 'train_rec_macro']\n",
        "\n",
        "    \n",
        "    #train_accuracy = accuracy_score(y_train_enc, pipeline.predict(X_train))\n",
        "    \n",
        "    test_accuracy = accuracy_score(y_test_enc, pipeline.predict(X_test))\n",
        "    \n",
        "    ave_macro_recall = recall_score(y_test_enc, pipeline.predict(X_test), average='macro')\n",
        "    recall_scores = recall_score(y_test_enc, pipeline.predict(X_test), average=None)\n",
        "    \n",
        "    test_results = np.append(np.array([min_df, train_accuracy, test_accuracy, ave_macro_recall]),\n",
        "                             recall_scores, score_mean)\n",
        "    \"\"\"\n",
        "    a = scores['test_accuracy'].mean()\n",
        "    f = scores['test_f1'].mean()\n",
        "    p = scores['test_precision'].mean()\n",
        "    r = scores['test_recall'].mean()\n",
        "    test_results = np.append(np.array([min_df, a, f, p]),r)\n",
        "    \n",
        "    \n",
        "   \n",
        "    return test_results\n",
        "    "
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-10T17:35:26.888718Z",
          "start_time": "2020-09-10T17:33:59.278764Z"
        },
        "scrolled": true,
        "id": "qVbFOtXQKomt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03db476b-aaaa-4415-860d-379b2cbe7c8c"
      },
      "source": [
        "metrics_summary = []\n",
        "\n",
        "for min_df in range(1,11):\n",
        "    test_scores = train_and_eval_model(min_df)\n",
        "    metrics_summary.append(test_scores)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MINIMUM DOCUMENT FREQUENCY = 1\n",
            "\n",
            "MINIMUM DOCUMENT FREQUENCY = 2\n",
            "\n",
            "MINIMUM DOCUMENT FREQUENCY = 3\n",
            "\n",
            "MINIMUM DOCUMENT FREQUENCY = 4\n",
            "\n",
            "MINIMUM DOCUMENT FREQUENCY = 5\n",
            "\n",
            "MINIMUM DOCUMENT FREQUENCY = 6\n",
            "\n",
            "MINIMUM DOCUMENT FREQUENCY = 7\n",
            "\n",
            "MINIMUM DOCUMENT FREQUENCY = 8\n",
            "\n",
            "MINIMUM DOCUMENT FREQUENCY = 9\n",
            "\n",
            "MINIMUM DOCUMENT FREQUENCY = 10\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-10T17:35:26.913147Z",
          "start_time": "2020-09-10T17:35:26.890840Z"
        },
        "id": "MAlgX9MYKomu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "3948670e-d686-4684-8136-f7ab5081844a"
      },
      "source": [
        "metrics_summary_df = pd.DataFrame(metrics_summary, \n",
        "                                  columns=['min doc freq',\n",
        "                                           'accuracy',\n",
        "                                           'f1',\n",
        "                                           'precision',\n",
        "                                          'recall'\n",
        "                                          ])\n",
        "\n",
        "metrics_summary_df"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>min doc freq</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>f1</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.898</td>\n",
              "      <td>0.896703</td>\n",
              "      <td>0.920915</td>\n",
              "      <td>0.880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.885</td>\n",
              "      <td>0.882302</td>\n",
              "      <td>0.912120</td>\n",
              "      <td>0.862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.0</td>\n",
              "      <td>0.882</td>\n",
              "      <td>0.878941</td>\n",
              "      <td>0.907666</td>\n",
              "      <td>0.860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.876</td>\n",
              "      <td>0.873796</td>\n",
              "      <td>0.899135</td>\n",
              "      <td>0.858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.876</td>\n",
              "      <td>0.873644</td>\n",
              "      <td>0.899578</td>\n",
              "      <td>0.856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.874</td>\n",
              "      <td>0.870894</td>\n",
              "      <td>0.900009</td>\n",
              "      <td>0.850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7.0</td>\n",
              "      <td>0.875</td>\n",
              "      <td>0.870304</td>\n",
              "      <td>0.900599</td>\n",
              "      <td>0.850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8.0</td>\n",
              "      <td>0.878</td>\n",
              "      <td>0.873350</td>\n",
              "      <td>0.906147</td>\n",
              "      <td>0.852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9.0</td>\n",
              "      <td>0.873</td>\n",
              "      <td>0.870201</td>\n",
              "      <td>0.899427</td>\n",
              "      <td>0.852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10.0</td>\n",
              "      <td>0.870</td>\n",
              "      <td>0.864790</td>\n",
              "      <td>0.904170</td>\n",
              "      <td>0.840</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   min doc freq  accuracy        f1  precision  recall\n",
              "0           1.0     0.898  0.896703   0.920915   0.880\n",
              "1           2.0     0.885  0.882302   0.912120   0.862\n",
              "2           3.0     0.882  0.878941   0.907666   0.860\n",
              "3           4.0     0.876  0.873796   0.899135   0.858\n",
              "4           5.0     0.876  0.873644   0.899578   0.856\n",
              "5           6.0     0.874  0.870894   0.900009   0.850\n",
              "6           7.0     0.875  0.870304   0.900599   0.850\n",
              "7           8.0     0.878  0.873350   0.906147   0.852\n",
              "8           9.0     0.873  0.870201   0.899427   0.852\n",
              "9          10.0     0.870  0.864790   0.904170   0.840"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-10T17:35:35.781715Z",
          "start_time": "2020-09-10T17:35:26.915324Z"
        },
        "scrolled": false,
        "id": "Rdb6Iq5IKomw"
      },
      "source": [
        "_,conf_matrix, y_pred = train_and_eval_model(min_df=2)\n",
        "labels = ['Negative', 'Postive']\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
        "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
        " \n",
        "plt.xlabel('Predictions', fontsize=18)\n",
        "plt.ylabel('Actuals', fontsize=18)\n",
        "ax.set_xticklabels([''] + labels)\n",
        "ax.set_yticklabels([''] + labels)\n",
        "plt.title('Confusion Matrix', fontsize=18)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WR19SdGrryS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCvYWRfSZzAp"
      },
      "source": [
        "df2 = pd.DataFrame()\n",
        "\n",
        "df2['X_test'] =  X_test\n",
        "df2['y_test_enc'] =  y_test\n",
        "df2['y_pred'] =  y_pred-1\n",
        "\n",
        "df2[df2[\"y_test_enc\"]==-1 & df2[\"y_pred\"]==1].item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svYVN2FWzaSB"
      },
      "source": [
        "df2[np.logical_and.reduce([df2['y_test_enc'] == -1, df2['y_pred'] == 0])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7E9ZwNr0YYZ"
      },
      "source": [
        "df.loc[852,'tweet']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jleixtSLxyRE"
      },
      "source": [
        "df2[df2[\"y_test_enc\"]==-1 & df2[\"y_pred\"]==1].item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2s63wZBKomw"
      },
      "source": [
        "# Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUyZmdx4Komx"
      },
      "source": [
        "The addition of SMOTE oversampling generally improved the SVM as negative classes have better scores. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQ5vPdYv4IWL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1ewKsB54JzC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXEuNdQm4JOr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqimPqBp5mLj"
      },
      "source": [
        "easy.py"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}